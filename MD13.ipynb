{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV file into DataFrame and extract time components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV(infile): \n",
    "    \"\"\"\n",
    "    Description: \n",
    "        1. Reads the input CSV file into a Pandas DataFrame. \n",
    "        2. Unifies Date and time formats and extracts day of the week for each observation.\n",
    "    Arguments:\n",
    "        infile: String value of input CSV file name.\n",
    "    Returns:\n",
    "        dataframe: Pandas DataFrame of observation with three extracted columns: NEW_DATE, NEW_TIME & DAY_WEEK.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    dataframe = pd.read_csv(infile, dtype=object, error_bad_lines=False, warn_bad_lines=False, low_memory=False)\n",
    "    \n",
    "    dataframe['NEW_DATE'] = pd.Series(pd.DatetimeIndex(dataframe['ACC_DATE']).date)\n",
    "    dataframe['NEW_TIME'] = pd.Series(pd.DatetimeIndex(dataframe['ACC_TIME']).hour)\n",
    "    dataframe['DAY_WEEK'] = pd.Series(pd.DatetimeIndex(dataframe['ACC_DATE']).dayofweek) #Monday=0, Sunday=6\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generate accidents count data set by grid cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countData(dataframe): \n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Generates an array of cell id, time of the day (0-23) and count of accidents per cell.\n",
    "    Arguments:\n",
    "        dataframe: Input Pandas DataFrame of observations.\n",
    "    Returns:\n",
    "        arr: NumPy array with 3 columns of cell id, time of the day & count (of accidents per cell).\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np \n",
    "    from collections import defaultdict\n",
    "    \n",
    "    dd = defaultdict(int)\n",
    "    \n",
    "    # generate dictionary of counts per cell\n",
    "    for row in df[['id', 'NEW_TIME']].itertuples():\n",
    "        for hour in np.arange(24):\n",
    "            dd.setdefault((row[1], hour), 0)\n",
    "    \n",
    "        dd[(row[1], row[2])] += 1\n",
    "    \n",
    "    # convert dictionary to array \n",
    "    arr = np.ndarray([len(dd),3], dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    for k, v in dd.items():\n",
    "        arr[idx, 0], arr[idx, 1] = k\n",
    "        arr[idx, 2] = v\n",
    "        idx += 1 \n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build time series and prepare dataset for supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Frames a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a DataFrame of observations in each grid cell using Rolling Window method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def walkForwardValidate(dataframe): \n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Generates training and test data sets from time series data set. \n",
    "    Arguments:\n",
    "        dataframe: Pandas DataFrame of observations.\n",
    "    Returns:\n",
    "        model: A dictionary containting estimator object (RF), RMSE and size of training dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np \n",
    "    from math import sqrt\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    \n",
    "    # Create 3 splits in time series data set\n",
    "    n_records = dataframe.shape[0]\n",
    "    n_train = int(n_records / 3)\n",
    "    \n",
    "    # initialize \n",
    "    min_rmse = 1000\n",
    "    model = {}\n",
    "    \n",
    "    for i in range(n_train, n_records):\n",
    "        train, test = dataframe.iloc[0:i,:].as_matrix(), dataframe.iloc[i:i+1,:].as_matrix()\n",
    "        X_train, X_test = train[:,:-1], test[:,:-1]\n",
    "        y_train, y_test = train[:,-1], test[:,-1]\n",
    "        \n",
    "        # tune hyperparameters\n",
    "        for n_estimators in np.arange(10,21): # changed upper limit from 31 to 21\n",
    "            for max_depth in np.arange(1,5):  # changed upper limit from 7 to 5\n",
    "                \n",
    "                # train Random Forest models\n",
    "                estimator = RandomForestRegressor(n_estimators=n_estimators, \n",
    "                                                  max_depth=max_depth, \n",
    "                                                  random_state=313, \n",
    "                                                  n_jobs=-1)\n",
    "                estimator.fit(X_train, y_train)\n",
    "                \n",
    "                # calculate performance metric(s)\n",
    "                y_pred = estimator.predict(X_test)\n",
    "                \n",
    "                rmse = sqrt(mean_squared_error(y_test, estimator.predict(X_test))) # RMSE\n",
    "                #mae = mean_absolute_error(y_test, y_pred)\n",
    "                \n",
    "                # compare model RMSE with existing minimum and save the best model\n",
    "                if rmse < min_rmse: \n",
    "                    min_rmse = rmse\n",
    "                    model['estimator'], model['RMSE'], model['train_size'] = estimator, min_rmse, int(len(X_train))\n",
    "                    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate predictor objects for the selected subset of grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cellEstimator(observationDict): \n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Generates time series dataset for the input grid cell and fits an estimator model to it. \n",
    "    Arguments:\n",
    "        observationDict: Dictionary containing observation DataFrames for all cells. \n",
    "    Returns: \n",
    "        cellModels: Text file containing a dictionary with cell id as key, and a dictionary of estimator model \n",
    "        resulted from walkForwardValidate function as value. \n",
    "    \"\"\"\n",
    "    \n",
    "    import _pickle as cPickle \n",
    "\n",
    "    with open('cellModels.txt', 'wb') as fout:\n",
    "\n",
    "        for cell in observationDict.keys(): \n",
    "\n",
    "            cmodel = {}\n",
    "\n",
    "            # extract obsevation datafrmae\n",
    "            tsDataFrame = observationDict[cell]\n",
    "\n",
    "            # build the estimator\n",
    "            cmodel = walkForwardValidate(tsDataFrame)\n",
    "\n",
    "            # save results to file\n",
    "            cPickle.dump((cell, cmodel), fout)\n",
    "            \n",
    "        fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read cell estimator file into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCellModels(infile='cellModels.txt'): \n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Reads binary file storing best estimator model for each cell into a dictionary. \n",
    "    Arguments: \n",
    "        infile: String value of file name where results from cellEstimator() are stored (default='cellModels.txt'). \n",
    "    Returns: \n",
    "        cellModels: Dictionary with grid cell id as key and RF model as value. \n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import _pickle as cPickle\n",
    "    \n",
    "    cellModels = {}\n",
    "\n",
    "    with open(infile, 'rb') as fin:\n",
    "        while True:\n",
    "            try:\n",
    "                # unpickle (load) input file\n",
    "                value = cPickle.load(fin)\n",
    "                \n",
    "                # save estimator to new dictionary with cell id as key\n",
    "                cellModels[value[0]] = value[1]['estimator']\n",
    "\n",
    "            except (EOFError):\n",
    "                break\n",
    "\n",
    "        fin.close()\n",
    "    \n",
    "    return cellModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build prediction output data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gridPredictor(dataDict, estimatatorDict, hour):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Predicts number of accidents in each grid for a given hour. \n",
    "    Arguments:\n",
    "        dataDict: A Dictionary with grid cell id as key and observations DataFrame as value (default=grid_ts).\n",
    "        estimatorDict: A Dictionary with grid cell id as key and RF model as value (default=cellDict). \n",
    "        hour: Hour of the day (0-23) at which prediction will be made.\n",
    "    Returns:\n",
    "        outfile: A CSV file containing an array of grid cell ids and predicted number of accidents. \n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import csv \n",
    "    \n",
    "    with open('Predicted_Counts.csv', 'w') as outfile: \n",
    "        # create writer object\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        # write column names\n",
    "        writer.writerow(['cell', 'pred_count'])\n",
    "        \n",
    "        try: \n",
    "            if not (hour in np.arange(24)): \n",
    "                raise ValueError('Input hour value is out of range (0 to 23).')\n",
    "\n",
    "            for cell in dataDict.keys():\n",
    "                # extract input data set from grid dictionary\n",
    "                observed = dataDict[cell].iloc[dataDict[cell].index == hour, :3]\n",
    "\n",
    "                # run prediction algorithm\n",
    "                model = estimatatorDict[cell]\n",
    "                predicted = np.ceil(model.predict(observed)) \n",
    "\n",
    "                # save results to outfile\n",
    "                writer.writerow([str(cell), int(predicted)])\n",
    "\n",
    "            outfile.close()\n",
    "\n",
    "        except ValueError as e:\n",
    "            print('ValueError: %s' % e.message)\n",
    "        except MemoryError as e:\n",
    "            print('MemoryError: %s' % e.message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate observations DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call readCSV function\n",
    "df = readCSV(infile='ALL_JOIN_FIPS1900_Join_GRID.csv')\n",
    "\n",
    "# Filter out grid cells within the municipal boundary of Baltimore (MUNI_CODE = '999')\n",
    "df = df.query(\"MUNI_CODE == '999'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate accidents count array & save to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "data = countData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a dictionary of all cells in the grid with associated supervised learning data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_ts = {}\n",
    "\n",
    "for cell in data[:,0]:\n",
    "    grid_ts[cell] = series_to_supervised(data=list(data[data[:,0] == cell, 2]), n_in=3, n_out=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>SKIP THIS BLOCK</font>\n",
    "#### <font color=green>Results are provided in cellModels.txt file and loaded in the next block.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train estimator models by cell\n",
    "# cellEstimator(observationDict=grid_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Read cell estimator file into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cellDict = readCellModels(infile='cellModels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict number of accidents for each cell at a specific hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridPredictor(dataDict=grid_ts, estimatatorDict=cellDict, hour=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract observed counts for hour = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Observed_Counts_17.csv\", \"w\") as outfile: \n",
    "    # writer object\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # write column names\n",
    "    writer.writerow(['cell','hour','count'])\n",
    "    \n",
    "    # save results array to .CSV file\n",
    "    writer.writerows(data[data[:,1] == 17, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
